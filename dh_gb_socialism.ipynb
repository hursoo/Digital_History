{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP42GD8DMWOLBjox6DP0NFI",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/hursoo/Digital_History/blob/main/dh_gb_socialism.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1_데이터 불러오기"
      ],
      "metadata": {
        "id": "bsc3w6NNkjeW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) 라이브러리, 구글 마운트"
      ],
      "metadata": {
        "id": "X_oVrgdHvxl9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "czemPwY7S86p"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "-rQDfuidTZuI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) 파일 불러오기"
      ],
      "metadata": {
        "id": "lBodLxDFwHf8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "base_path = '/content/drive/MyDrive/Digital_History(230829)/'\n",
        "file01 = '1_gb_sent.xlsx'\n",
        "file02 = '2_r_ho.xlsx'\n",
        "file03 = '3_ho_grid.xlsx'"
      ],
      "metadata": {
        "id": "2sM7OP1OTxpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent = pd.read_excel(base_path + file01)\n",
        "r = pd.read_excel(base_path + file02)\n",
        "ho = pd.read_excel(base_path + file03)"
      ],
      "metadata": {
        "id": "30gbS5ASTxr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sent[:3]"
      ],
      "metadata": {
        "id": "dhphzJsknojS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r[:3]"
      ],
      "metadata": {
        "id": "xdjmh3BhrQ1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "r1 = r.iloc[:,:4] # merge시 중복 피하기 위해 ho_no 제외\n",
        "r1[:3]"
      ],
      "metadata": {
        "id": "blZZEnXEnuiT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ho[:3]"
      ],
      "metadata": {
        "id": "prmjd64qnuf9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) db 병합하기"
      ],
      "metadata": {
        "id": "LiSEwB2nsBj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "temp1 = pd.merge(sent, r1, left_on = 'r_no', right_on = 'r_id', how = 'inner')\n",
        "temp2 = pd.merge(temp1, ho, left_on = 'ho_no', right_on = 'ho_id', how = 'inner')\n",
        "temp2[:3]"
      ],
      "metadata": {
        "id": "G1EWZDtGnudN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 필요한 열만 필요한 순서대로 바꾸기\n",
        "df = temp2[['sent_id',  'sent_raw',  'sent_split',  'r_no',  'title',  'writer',  'w_new',  'ho_no',  'year',  'month',  'grid']]\n",
        "print(df.shape)\n",
        "df[:3]"
      ],
      "metadata": {
        "id": "Mo7-8jBVtADE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_excel(base_path + 'gb_corpus.xlsx')"
      ],
      "metadata": {
        "id": "bk1lsMLPN_Bl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2_논조를 반영하는 특성 추출"
      ],
      "metadata": {
        "id": "3coKMcoakqvA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) 문서-단어 행렬(dtm) 산출 함수"
      ],
      "metadata": {
        "id": "V033pPNU84lr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dtm(df, col_name, stopw, rank_n): # rank_n : 고빈도 단어 n 순위까지\n",
        "    # 단어 종류 모두 벡터화. 2음절 이상\n",
        "    tv = TfidfVectorizer(stop_words=stopw, norm=None)\n",
        "    dtm = tv.fit_transform(df[col_name])\n",
        "\n",
        "    # df 형태로 표시\n",
        "    dtm_df = pd.DataFrame(dtm.toarray(), columns=tv.get_feature_names_out(), index=df.index)\n",
        "\n",
        "    highword_list = dtm_df.sum().sort_values(ascending=False)[:rank_n].index.to_list()\n",
        "    feature_df = dtm_df[highword_list] # 열 순서는 tfidf값이 높은 것부터 낮은 순으로 정렬\n",
        "    return feature_df"
      ],
      "metadata": {
        "id": "WKcsjlUFvaB0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) 특성 및 특성벡터\n",
        "- tfidf 고빈도 50위 단어"
      ],
      "metadata": {
        "id": "XsE02yQ11ioy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stopword_3 = ['문제', '금일', '관계'] # 제외할 단어\n",
        "\n",
        "dtm50_df = get_dtm(df, 'sent_split', stopword_3, 50)\n",
        "dtm50_df"
      ],
      "metadata": {
        "id": "kxa9TOaH08MV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3_시기 구분하기\n",
        "- 시기 구분 : 논조 변화를 관찰하는 마디"
      ],
      "metadata": {
        "id": "oZwHdPOZIfqH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) dtm50 + 구간(grid) = gtm50 산출하기"
      ],
      "metadata": {
        "id": "405_v8joIl0_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def transform_to_gtm(df, grid_col, dtm_df): # 인자 - df, 구간 정보 열, dtm50_df\n",
        "    # 구간정보만 df로 추출\n",
        "    grid_df = df[[grid_col]]\n",
        "    # 구간 정보 결합하고, 구간을 index로 만듦\n",
        "    temp_dtm = pd.concat([dtm_df, grid_df], axis=1)\n",
        "    grid_dtm = temp_dtm.set_index(grid_col)\n",
        "    # 구간별 평균\n",
        "    gtm = grid_dtm.groupby(grid_col).mean()\n",
        "    return gtm"
      ],
      "metadata": {
        "id": "rVPeiAe8p2_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 함수 실행하여 gtm 변수에 할당\n",
        "gtm_df = transform_to_gtm(df, 'grid', dtm50_df)\n",
        "gtm_df"
      ],
      "metadata": {
        "id": "M8qkSeHFp28l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) 구간별 상관계수 산출하기"
      ],
      "metadata": {
        "id": "6KDAJhO-Itq4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_corr(gtm):\n",
        "    tgm = gtm.T\n",
        "    result = tgm.corr()\n",
        "    return result"
      ],
      "metadata": {
        "id": "BQEwo6Y5p25k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gg_corr = make_corr(gtm_df)\n",
        "gg_corr"
      ],
      "metadata": {
        "id": "7rnwUSRxp22u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) 히트맵 시각화로 시기구분 하기"
      ],
      "metadata": {
        "id": "1Rahm6_5I28I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def draw_heatmap(df):\n",
        "    df = df.copy()\n",
        "    plt.figure(figsize=(10,4))\n",
        "    sns.heatmap(data = df, annot=True,\n",
        "    fmt = '.3f', linewidths=.5, cmap='Blues')"
      ],
      "metadata": {
        "id": "v-RB0dYfp2zs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "draw_heatmap(gg_corr)"
      ],
      "metadata": {
        "id": "32ArkQbtp2wz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- 모호한 부분의 시기 구분  \n",
        " - 해당 구간이 좌우와 가진 상관계수를 비교  \n",
        " - 이 때 비교 범위는 왼쪽(및 오른쪽) 가상 시기에 포함되는 구간들의 상관계수를 평균한 값  \n",
        " =>   \n",
        "    1p : 01hf - 05hf  \n",
        "    2p : 06hf - 09hf  \n",
        "    3p : 10hf - 12hf"
      ],
      "metadata": {
        "id": "-wlGq_8Ur97b"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4) 시기별 코퍼스 산출"
      ],
      "metadata": {
        "id": "eltl2FS0r94b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "prd_1 = ['01hf', '02hf', '03hf', '04hf', '05hf']\n",
        "prd_2 = ['06hf', '07hf', '08hf', '09hf']\n",
        "prd_3 = ['10hf', '11hf', '12hf']"
      ],
      "metadata": {
        "id": "0IA6kWz1z4z-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.copy()\n",
        "df['period'] = '' # df에 새 열('period')을 생성\n",
        "df.loc[df['grid'].isin(prd_1), 'period'] = '1p'\n",
        "df.loc[df['grid'].isin(prd_2), 'period'] = '2p'\n",
        "df.loc[df['grid'].isin(prd_3), 'period'] = '3p'\n",
        "df"
      ],
      "metadata": {
        "id": "vflOPcNhz4xM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 시기구분 정보 반영 검증\n",
        "df.groupby(['period', 'grid'])['sent_id'].count()"
      ],
      "metadata": {
        "id": "_sd0PqjA3ynH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 시기별 코퍼스\n",
        "\n",
        "df_1p = df[df['period'] == '1p']\n",
        "df_2p = df[df['period'] == '2p']\n",
        "df_3p = df[df['period'] == '3p']"
      ],
      "metadata": {
        "id": "RIGp1b45qTfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_1p.shape)\n",
        "print(df_2p.shape)\n",
        "print(df_3p.shape)\n",
        "print(df_1p.shape[0] + df_2p.shape[0] + df_3p.shape[0])"
      ],
      "metadata": {
        "id": "UqUIMTe6yCDT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4_시기별 연결망 계수, 지표 산출"
      ],
      "metadata": {
        "id": "uBnfKi3X7og1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) 시기별 코사인유사도 계수"
      ],
      "metadata": {
        "id": "nvX2P706yCAq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 코사인유사도 산출 함수\n",
        "\n",
        "def get_cossim(dtm_df):\n",
        "    tdf_n = dtm_df.columns.tolist()\n",
        "    tdm = dtm_df.T\n",
        "    cossim = cosine_similarity(tdm, tdm)\n",
        "    cossim_df = pd.DataFrame(cossim, columns=tdf_n, index=tdf_n)\n",
        "    return cossim_df"
      ],
      "metadata": {
        "id": "VOjF1YtT5FGC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 시기별 dtm 산출\n",
        "\n",
        "stopword_3 = ['문제', '금일', '관계'] # 제외할 단어\n",
        "dtm50_df_1p = get_dtm(df_1p, 'sent_split', stopword_3, 50)\n",
        "dtm50_df_2p = get_dtm(df_2p, 'sent_split', stopword_3, 50)\n",
        "dtm50_df_3p = get_dtm(df_3p, 'sent_split', stopword_3, 50)"
      ],
      "metadata": {
        "id": "TNQ-QGPucRHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(dtm50_df_1p.shape)\n",
        "print(dtm50_df_2p.shape)\n",
        "print(dtm50_df_3p.shape)"
      ],
      "metadata": {
        "id": "gdyHrqZoc33d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 시기별 코사인 유사도 산출 함수 실행\n",
        "\n",
        "cossim_1p = get_cossim(dtm50_df_1p)\n",
        "cossim_2p = get_cossim(dtm50_df_2p)\n",
        "cossim_3p = get_cossim(dtm50_df_3p)"
      ],
      "metadata": {
        "id": "F_dosNkQdM6F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(cossim_1p.iloc[:3,:5])\n",
        "print(cossim_2p.iloc[:3,:5])\n",
        "print(cossim_3p.iloc[:3,:5])"
      ],
      "metadata": {
        "id": "_HJHfSgzdWOV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) wnet.exe 입력값 작성"
      ],
      "metadata": {
        "id": "Pyb_m3G7zEAZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 코사인유사도 df를 그대로 텍스트 파일(tsv)로 저장 (인덱스, 헤더 모두 출력하도록 해야 고빈도 50개 단어가 출력됨)\n",
        "\n",
        "cossim_1p.to_csv(base_path + 'result/12_wnet_input_1p.txt', index=True, header=True, sep='\\t')\n",
        "cossim_2p.to_csv(base_path + 'result/12_wnet_input_2p.txt', index=True, header=True, sep='\\t')\n",
        "cossim_3p.to_csv(base_path + 'result/12_wnet_input_3p.txt', index=True, header=True, sep='\\t')"
      ],
      "metadata": {
        "id": "SYLzxdeQzD9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) nc.exe 입력값 작성"
      ],
      "metadata": {
        "id": "2gPTsxS4zD55"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# nc(지역중심성) 산출 위한 입력값 만들기 - \"동일단어-동일단어\" 제거. 2,500행 -> 2,450행\n",
        "\n",
        "def cossim_to_ncinput(df):\n",
        "    # df : 코사인유사도 df\n",
        "    df1 = pd.DataFrame(df.unstack())\n",
        "    not_same_index = [(m,n) for m, n in df1.index if (m != n)]\n",
        "    not_same_df = df1.loc[not_same_index]\n",
        "    return not_same_df"
      ],
      "metadata": {
        "id": "SmxF4pRmyB9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# nc(지역중심성) 산출 위한 입력값 만들기 - \"동일단어-동일단어\" 제거. 2,500행 -> 2,450행\n",
        "# 텍스트 파일(tsv)로 저장\n",
        "\n",
        "cossim_to_ncinput(cossim_1p).to_csv(base_path + 'result/12_ncinput_1p.txt', header=False, sep='\\t')\n",
        "cossim_to_ncinput(cossim_2p).to_csv(base_path + 'result/12_ncinput_2p.txt', header=False, sep='\\t')\n",
        "cossim_to_ncinput(cossim_3p).to_csv(base_path + 'result/12_ncinput_3p.txt', header=False, sep='\\t')"
      ],
      "metadata": {
        "id": "A4AMqhyM3QM0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4) 계수,지표 산출(윈도우 커맨드)\n",
        "- wnet.exe\n",
        "- nc.exe\n",
        "- 결과 파일을 다시 구글드라이브의 data 폴더에 업로드"
      ],
      "metadata": {
        "id": "mH8ILOER8JE5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5_노드엑셀 입력값 산출"
      ],
      "metadata": {
        "id": "NZ0ZtzAAGj0O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) 중복순서쌍 제거"
      ],
      "metadata": {
        "id": "Tf3J1yOlHawS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PFNet 파일 불러오기\n",
        "pfnet_1p = pd.read_csv(base_path + 'data/PFNet-12_wnet_input_1p.txt', sep='\\t')\n",
        "pfnet_2p = pd.read_csv(base_path + 'data/PFNet-12_wnet_input_2p.txt', sep='\\t')\n",
        "pfnet_3p = pd.read_csv(base_path + 'data/PFNet-12_wnet_input_3p.txt', sep='\\t')"
      ],
      "metadata": {
        "id": "2xGA7RvW8JBz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pfnet_1p"
      ],
      "metadata": {
        "id": "BL9dv4O_9ctv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 순서만 다르고 요소는 같은 순서쌍 중 하나를 제거하는 함수\n",
        "\n",
        "def remove_same_pairwords(df):  # df : pfnet df\n",
        "\n",
        "    # df에서 단어 순서쌍만 리스트로 추출\n",
        "    df_num = df.index.tolist()\n",
        "    ww_list = []\n",
        "    for i in df_num:\n",
        "        ww_list.append(df.iloc[i,:2].tolist())\n",
        "    ww_list\n",
        "\n",
        "    # 순서쌍의 원소가 동일 단어인 경우 추출\n",
        "    dupli_num=[]\n",
        "    for i, (x, y) in enumerate(ww_list):\n",
        "        if [y, x] in ww_list:\n",
        "            dupli_num.append(i)\n",
        "    dupli_num\n",
        "\n",
        "    # 순서쌍이 동일한 것 중 하나만 남겨 df 출력\n",
        "    if len(dupli_num) > 0: # 중복 순서쌍 있을 경우\n",
        "        only_one = [k for k in df_num if k not in dupli_num] # 중복 안되는 index 일단 추출\n",
        "        del_dupli = only_one + [dupli_num[0]] # 중복되는 것 중 하나만 index 추가\n",
        "        del_dupli.sort() # index 정렬\n",
        "        result = df.iloc[del_dupli] # index로 df 불러옴\n",
        "        result1 = result.reset_index(drop=True) # index를 새로 고침\n",
        "        return result1\n",
        "    else:  # 중복되는 것 없으면 그대로 df 출력\n",
        "        return df"
      ],
      "metadata": {
        "id": "3VzD17RY0ja9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pfnet_1p_df = remove_same_pairwords(pfnet_1p)\n",
        "pfnet_2p_df = remove_same_pairwords(pfnet_2p)\n",
        "pfnet_3p_df = remove_same_pairwords(pfnet_3p)"
      ],
      "metadata": {
        "id": "nUaAr4C847GK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pfnet_1p_df[:3]"
      ],
      "metadata": {
        "id": "Ao0yfOOHCFgp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2) 코사인유사도 등급화"
      ],
      "metadata": {
        "id": "FEfR5nJz8I_R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# weight 값을 범주형으로 (5등분) for 링크(엣지) 시각화\n",
        "\n",
        "def transform_wgt_to_grade(df, col_name, grade_no): # col_name : '[Weight]'\n",
        "    df_c = df.copy() # 입력 df 자체의 weight가 변화하는 것 방지용\n",
        "\n",
        "    # 등급(grade) 간 격차를 0.5로 설정\n",
        "    df_c[col_name] = pd.qcut(df_c[col_name], q=grade_no, labels=list(np.arange(1,1+grade_no/2,0.5)))\n",
        "\n",
        "    # 열 이름을 알기 쉽게 변경\n",
        "    df1 = df_c.rename(columns = {'[Node1]' : 'node1',\n",
        "                                '[Node2]' : 'node2',\n",
        "                                '[Weight]': 'weight'})\n",
        "    return df1"
      ],
      "metadata": {
        "id": "aH3LTcnE6ksk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pfnet_1p_df_simple_wgt = transform_wgt_to_grade(pfnet_1p_df, '[Weight]', 5)\n",
        "pfnet_2p_df_simple_wgt = transform_wgt_to_grade(pfnet_2p_df, '[Weight]', 5)\n",
        "pfnet_3p_df_simple_wgt = transform_wgt_to_grade(pfnet_3p_df, '[Weight]', 5)"
      ],
      "metadata": {
        "id": "yAkfC78K6kpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 구분 검증\n",
        "pfnet_1p_df_simple_wgt['weight'].value_counts().to_frame() # weight 값을 값별로 센 결과(시리즈)를 데이터프레임으로 변경"
      ],
      "metadata": {
        "id": "2ny5n8oq8I8O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 엑셀 파일로 저장하기\n",
        "\n",
        "pfnet_1p_df_simple_wgt.to_excel(base_path + 'result/12_pfnet_1p_nodexl.xlsx')\n",
        "pfnet_2p_df_simple_wgt.to_excel(base_path + 'result/12_pfnet_2p_nodexl.xlsx')\n",
        "pfnet_3p_df_simple_wgt.to_excel(base_path + 'result/12_pfnet_3p_nodexl.xlsx')"
      ],
      "metadata": {
        "id": "NNZ4keQ1DPe5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3) 군집 및 중심성 정보 정리"
      ],
      "metadata": {
        "id": "V6b2dp9y8I5s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# PNNC 파일 불러오기\n",
        "pnnc_1p = pd.read_csv(base_path + 'data/PNNC-12_wnet_input_1p.txt', sep='\\t')\n",
        "pnnc_2p = pd.read_csv(base_path + 'data/PNNC-12_wnet_input_2p.txt', sep='\\t')\n",
        "pnnc_3p = pd.read_csv(base_path + 'data/PNNC-12_wnet_input_3p.txt', sep='\\t')\n",
        "\n",
        "# WCENT 파일 불러오기\n",
        "wcent_1p = pd.read_csv(base_path + 'data/WCENT-12_wnet_input_1p.txt', sep='\\t')\n",
        "wcent_2p = pd.read_csv(base_path + 'data/WCENT-12_wnet_input_2p.txt', sep='\\t')\n",
        "wcent_3p = pd.read_csv(base_path + 'data/WCENT-12_wnet_input_3p.txt', sep='\\t')\n",
        "\n",
        "# NC 파일 불러오기\n",
        "nc_1p = pd.read_csv(base_path + 'data/nc_2.0_12_ncinput_1p.txt', sep='\\t')\n",
        "nc_2p = pd.read_csv(base_path + 'data/nc_2.0_12_ncinput_2p.txt', sep='\\t')\n",
        "nc_3p = pd.read_csv(base_path + 'data/nc_2.0_12_ncinput_3p.txt', sep='\\t')"
      ],
      "metadata": {
        "id": "LXzaDY7IGhyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(pnnc_1p[:3])\n",
        "print(wcent_2p[:3])\n",
        "print(nc_3p[:3])"
      ],
      "metadata": {
        "id": "_wPn_dX3GPZl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# WNET0.4 결과물 중에서 꼭 필요한 세 지표만 산출하기\n",
        "\n",
        "def get_group_ctrlity(pnnc, wcent, nc):\n",
        "    group = pnnc\n",
        "    global_ctrlity = wcent\n",
        "    local_ctrlity = nc\n",
        "    a = group.merge(global_ctrlity[['NODE', 'rTBC(0~1)']], left_on='[Item]', right_on='NODE', how='inner')\n",
        "    b = a.merge(local_ctrlity, left_on='[Item]', right_on='[NODE]', how='inner')\n",
        "    b = b.drop(['[SN]', 'NODE', '[NODE]'], errors='ignore', axis=1)\n",
        "    return b"
      ],
      "metadata": {
        "id": "hg2N0t4fGPWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 그룹 및 중심성 지표 산출 함수 실행\n",
        "\n",
        "group_ctrlity_1p = get_group_ctrlity(pnnc_1p, wcent_1p, nc_1p)\n",
        "group_ctrlity_2p = get_group_ctrlity(pnnc_2p, wcent_2p, nc_2p)\n",
        "group_ctrlity_3p = get_group_ctrlity(pnnc_3p, wcent_3p, nc_3p)"
      ],
      "metadata": {
        "id": "pM3x1ea2GPTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(group_ctrlity_1p[:3])\n",
        "print(group_ctrlity_2p[:3])\n",
        "print(group_ctrlity_3p[:3])"
      ],
      "metadata": {
        "id": "A4ACpTn5GPQS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 엑셀로 저장하기\n",
        "\n",
        "group_ctrlity_1p.to_excel(base_path + 'result/12_group_ctrlity_1p_nodexl.xlsx')\n",
        "group_ctrlity_2p.to_excel(base_path + 'result/12_group_ctrlity_2p_nodexl.xlsx')\n",
        "group_ctrlity_3p.to_excel(base_path + 'result/12_group_ctrlity_3p_nodexl.xlsx')"
      ],
      "metadata": {
        "id": "npLLdTz3H5Lp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The End of Note"
      ],
      "metadata": {
        "id": "5RU0J8JkH5Ih"
      }
    }
  ]
}